{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**AASD 4015 Advanced Mathematical Concepts for Deep Learning\n",
        "Project 1: MNIST Handwriting Classification\n",
        "The project is conducted by Cheuk Yin Li 101386432, Eman Elsefy 101428470, Shui Hei Yung 101409756\n",
        "The dataset is extracted from MNIST. ***\n",
        "\n",
        "The project aims to classify images of handwriting words using a convolutional neural network (CNN) with hyperparameter tuning and fine-tuning techniques. The dataset consists of 60,000 training samples and 10,000 testing samples, with 10 classes in total (0-9). Deep learning approaches are used to train the model, which consists of convolution layers, a fully connected layer, dropout layer, and softmax layer. To optimize the model's performance, hyperparameter tuning techniques are applied, including adjusting the optimizer and the number of epochs used during training.\n",
        "\n",
        "In addition to hyperparameter tuning, fine-tuning techniques are also employed to further improve the model's accuracy. Fine-tuning involves taking a pre-trained neural network that was previously trained on a similar task and adjusting its parameters to improve its performance on the current task. In this project, we will use the pre-trained weights from a different dataset and fine-tune the model to classify handwriting words.\n",
        "\n",
        "By fine-tuning the pre-trained model on the current dataset, we can leverage the knowledge captured in the pre-trained weights and significantly reduce the time and resources needed to achieve high accuracy. The fine-tuning process will involve adjusting the model's architecture, retraining the fully connected layers, and fine-tuning the pre-trained weights to improve the model's accuracy on the current task.\n",
        "\n",
        "Through this project, we aim to showcase the effectiveness of fine-tuning techniques in improving the performance of deep learning models, specifically in the context of image classification tasks."
      ],
      "metadata": {
        "id": "4obkdHJN36u1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD2V59c92QwV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.applications import VGG16\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "MhOJLUWr2Sgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the shape of the training and testing data\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Training labels shape:\", y_train.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)\n",
        "print(\"Testing labels shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "bpar_HLj4ohP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 25 images in the training set\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.imshow(x_train[i], cmap=\"gray\")\n",
        "    plt.title(str(y_train[i]))\n",
        "    plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eaum05sN4sWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The class distribution is a nearly equal distributed which means the biases of data is relatively low.\n",
        "sns.barplot(class_counts, x=\"label\", y=\"count\")\n",
        "plt.title(\"Class distribution in train_df\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hOXd_mzw4zyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#By coloring the points based on their corresponding labels, we can visualize how the different classes are distributed in this space, and whether there are any clear patterns or clusters that separate them from each other.\n",
        "idx = np.random.randint(x_train.shape[0], size=500)\n",
        "x_train_sample = x_train[idx, :]\n",
        "y_train_sample = y_train[idx]\n",
        "\n",
        "# Fit PCA model to the data\n",
        "pca = PCA(n_components=2)\n",
        "x_train_pca = pca.fit_transform(x_train_sample.reshape(x_train_sample.shape[0], -1))\n",
        "\n",
        "# Plot the scatterplot\n",
        "plt.scatter(x_train_pca[:, 0], x_train_pca[:, 1], c=y_train[idx], cmap='tab10')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zS1pDxLp9-eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values to be between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0"
      ],
      "metadata": {
        "id": "tuSUUoeB2T7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape input data to match VGG16 input shape\n",
        "x_train = tf.image.grayscale_to_rgb(tf.expand_dims(x_train, axis=-1))\n",
        "x_test = tf.image.grayscale_to_rgb(tf.expand_dims(x_test, axis=-1))\n",
        "x_train = tf.image.resize(x_train, (48, 48))\n",
        "x_test = tf.image.resize(x_test, (48, 48))"
      ],
      "metadata": {
        "id": "cd7WgEnD2VYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the new shape of the data\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Testing data shape:\", x_test.shape)"
      ],
      "metadata": {
        "id": "fB1R9AA84_3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n"
      ],
      "metadata": {
        "id": "MGbsFQ552Wl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Freeze layers in the base model\n",
        "for layer in base_model.layers[:15]:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "m-eaMdkE2X-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model by adding additional layers on top of the base model\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "JG8Pllac2ZLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "sDIBd5kW2aYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation for training images\n",
        "train_datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1, width_shift_range=0.1, height_shift_range=0.1)\n",
        "train_datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "RyutJMEm7FfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kakChbM2blA",
        "outputId": "ae94d455-71c5-4acb-e08f-c4dac325a478"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1746/1875 [==========================>...] - ETA: 3:09 - loss: 0.0870 - accuracy: 0.9796"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "jmBmOE0v-MGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy over epochs\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ug7D2bEH7VAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "j84sMPNS-Q2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fit_model.history['accuracy'])\n",
        "plt.plot(fit_model.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(fit_model.history['loss'])\n",
        "plt.plot(fit_model.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TumFlyAr-VRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model by unfreezing more layers\n",
        "for layer in base_model.layers[10:]:\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "id": "MsLQIjM53Usb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=1e-5), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "t7rw1dXb3XUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model again with a lower learning rate\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "nFUYc47I3YeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "WTjH7PSY-I-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the accuracy over epochs again\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy (Fine-tuning)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mny__e8-7aPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "7RLL1zzG8VwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(fit_model.history['accuracy'])\n",
        "plt.plot(fit_model.history['val_accuracy'])\n",
        "\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(fit_model.history['loss'])\n",
        "plt.plot(fit_model.history['val_loss'])\n",
        "\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7LMg2iXI-V_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dgCYUF81FA0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}